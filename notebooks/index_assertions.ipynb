{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shelve\n",
    "import os\n",
    "import pickle\n",
    "import spacy\n",
    "\n",
    "index_fn = \"/data/assertion_shelve_wiki\"\n",
    "max_len = 50\n",
    "\n",
    "#nlp = spacy.load('en', disable=['parser', 'ner', 'textcat'])\n",
    "nlp = spacy.load('en', parser=False, entity=False, matcher=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "object2assertions = dict()\n",
    "subject2assertions = dict()\n",
    "assertions = dict()\n",
    "\n",
    "def lemmatized(tokens, start, end):\n",
    "    return \" \".join(t.lemma_ for t in tokens if t.idx < end and t.idx >= start)\n",
    "\n",
    "\n",
    "ctr = 0\n",
    "\n",
    "def process_line(l, source):\n",
    "    global ctr\n",
    "    #e.g.:  'pair of compasses synonym compass\\t0:17\\t26:33'\n",
    "    try:\n",
    "        l = l.strip()\n",
    "        if \"\\t\" not in l:\n",
    "            return\n",
    "\n",
    "        [text, subject_spans, object_spans] = l.split(\"\\t\")\n",
    "        \n",
    "        if text.count(\" \") < max_len:\n",
    "            tokens = nlp(text)\n",
    "            subjects = [lemmatized(tokens, int(s[:s.index(\":\")]), int(s[s.index(\":\") + 1:]))\n",
    "                        for s in subject_spans.split(\",\")]\n",
    "            objects = [lemmatized(tokens, int(s[:s.index(\":\")]), int(s[s.index(\":\") + 1:]))\n",
    "                       for s in object_spans.split(\",\")]\n",
    "\n",
    "            if len(subjects) == 1 and len(objects) == 1 and subjects[0] == objects[0]:\n",
    "                return\n",
    "\n",
    "            ctr += 1\n",
    "\n",
    "            for subject in subjects:\n",
    "                if subject not in subject2assertions[source]:\n",
    "                    subject2assertions[source][subject] = set()\n",
    "                subject2assertions[source][subject].add(str(ctr))\n",
    "\n",
    "            for obj in objects:\n",
    "                if obj not in object2assertions[source]:\n",
    "                    object2assertions[source][obj] = set()\n",
    "                object2assertions[source][obj].add(str(ctr))\n",
    "            assertions[str(ctr)] = text\n",
    "        #else:\n",
    "            #print(\"skipping assertion bigger than %d...\" % max_len)\n",
    "    except ValueError:\n",
    "        print(\"Could not process line: \" + l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing wikipedia_firstsent assertions...\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n",
      "2400000\n",
      "2500000\n",
      "2600000\n",
      "2700000\n",
      "2800000\n",
      "2900000\n",
      "3000000\n",
      "3100000\n",
      "3200000\n",
      "3300000\n",
      "3400000\n",
      "3500000\n",
      "3600000\n",
      "3700000\n",
      "3800000\n",
      "3900000\n",
      "4000000\n",
      "4100000\n",
      "4200000\n",
      "4300000\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(index_fn):\n",
    "    import shutil\n",
    "    shutil.rmtree(index_fn)\n",
    "    \n",
    "os.mkdir(index_fn)  \n",
    "\n",
    "\n",
    "def process_source(name, path):\n",
    "    global assertions, ctr\n",
    "    print(\"Processing %s assertions...\" % name)\n",
    "    object2assertions[name] = dict()\n",
    "    subject2assertions[name] = dict()\n",
    "    with open(path) as f:\n",
    "        for l in f:\n",
    "            process_line(l, name)\n",
    "            if ctr % 100000 == 0:\n",
    "                print(\"%d\" % ctr)\n",
    "                db.update(assertions)\n",
    "                del assertions\n",
    "                assertions = dict()\n",
    "\n",
    "with shelve.open(os.path.join(index_fn, 'assertions.shelve')) as db:\n",
    "    #process_source(\"dbpedia_type\", \"/run/media/diwe01/Data3/wiki/dbpedia/type_assertions.txt\") \n",
    "    #process_source(\"microsoft_type\", \"/run/media/diwe01/Data2/corpora/concepts/concepts_microsoft/data-concept/type_assertions.txt\") \n",
    "    #process_source(\"simple_wikipedia_firstsent\", \"/run/media/diwe01/Data3/wiki/simple_abstracts/wiki_assertions.txt\") \n",
    "    #process_source(\"en_wikt\", \"/run/media/diwe01/Data3/wiki/en_wikt/meaning_assertions.txt\") \n",
    "    process_source(\"wikipedia_firstsent\", \"/run/media/diwe01/Data3/wiki/en_abstracts/wiki_assertions.txt\") \n",
    "    #process_source(\"ppdb_L\", \"/run/media/diwe01/Data2/corpora/concepts/ppdb/assertions_pos.txt\") \n",
    "    #process_source(\"conceptnet\", \"/run/media/diwe01/Data2/corpora/concepts/conceptnet/assertions.txt\")\n",
    "\n",
    "    db.update(assertions)\n",
    "    \n",
    "\n",
    "with open(os.path.join(index_fn, 'subject2assertions.pkl'), \"wb\") as f:\n",
    "    pickle.dump(subject2assertions, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(os.path.join(index_fn, 'object2assertions.pkl'), \"wb\") as f:\n",
    "    pickle.dump(object2assertions, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "from projects.assertion_mr.shared import AssertionStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_store = AssertionStore(index_fn, [\"wikipedia_firstsent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jack.io.load import load_squad\n",
    "\n",
    "ds = load_squad('data/SQuAD/dev-v1.1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "q, answers = ds[500][0], ds[500][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jack.util import preprocessing\n",
    "from jack.util.vocab import Vocab\n",
    "\n",
    "v = Vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "qts, _, _, qls, _ = preprocessing.nlp_preprocess(q.question, v, use_spacy=True, with_lemmas=True)\n",
    "sts, _, _, sls, _ = preprocessing.nlp_preprocess(q.support[0], v, use_spacy=True, with_lemmas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ass = a_store.get_assertion_keys(qls, sls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What was media day called for Super Bowl 50?\n",
      "The game's media day, which was typically held on the Tuesday afternoon prior to the game, was moved to the Monday evening and re-branded as Super Bowl Opening Night. The event was held on February 1, 2016 at SAP Center in San Jose. Alongside the traditional media availabilities, the event featured an opening ceremony with player introductions on a replica of the Golden Gate Bridge.\n",
      "A: Super Bowl Opening Night.\n",
      "\n",
      "6.688068485821294e-05 ['day'] ---- ['Tuesday']\n",
      "tuesday is a day of the week occurring after monday and before wednesday.\n",
      "\n",
      "6.688068485821294e-05 ['day'] ---- ['Tuesday']\n",
      "tuesday is a day of the week.\n",
      "\n",
      "7.643506840938621e-05 ['day'] ---- ['afternoon']\n",
      "afternoon is that time of day from 1:00 pm and 5:00 pm.afternoon may also refer to:\n",
      "\n",
      "8.917424647761726e-05 ['day'] ---- ['evening']\n",
      "evening is the period of time near the end of the day, usually from 6:00pm to nighttime.\n",
      "\n",
      "1.1889899530348968e-05 ['day'] ---- ['Night']\n",
      "night is day is a 2012 independent feature film shot in glasgow, scotland.\n",
      "\n",
      "9.476427386875148e-06 ['day'] ---- ['Night']\n",
      "all days are nights: songs for lulu is the sixth studio album by canadian-american singer-songwriter rufus wainwright, first released in canada through decca records on march 23, 2010.\n",
      "\n",
      "2.0771020272515784e-05 ['media'] ---- ['media']\n",
      "media is a railroad station in the borough of media, pennsylvania, along the septa media/elwyn line, the former pennsylvania railroad west chester line.\n",
      "\n",
      "1.2934937265554262e-05 ['called'] ---- ['player']\n",
      "calls made during the auction phase of a contract bridge game convey information about the player's card holdings.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(q.question)\n",
    "print(q.support[0])\n",
    "print('A:', answers[0].text)\n",
    "print()\n",
    "for a in ass[0]:\n",
    "    print(ass[0][a], qts[ass[1][a][0][0]:ass[1][a][0][1]], '----', sts[ass[1][a][1][0]:ass[1][a][1][1]])\n",
    "    print(a_store.get_assertion(a))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, 3], [102, 103])"
      ]
     },
     "execution_count": 29,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "ass[1][a]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}